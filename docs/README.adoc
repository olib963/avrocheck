= Avrocheck

--
image::https://circleci.com/gh/olib963/avrocheck.svg?style=svg[link="https://circleci.com/gh/olib963/avrocheck", float="left"]
image::https://img.shields.io/maven-central/v/io.github.olib963/avrocheck.svg?style=plastic[link="http://mvnrepository.com/artifact/io.github.olib963/avrocheck", float="left"]
--

== What?

A small library to generate random ``GenericRecord``s from a given https://avro.apache.org/[Avro] schema using https://www.scalacheck.org/[ScalaCheck].

== Why?

First of all we always want to make sure that our custom deserialisation code is able to deserialise any message
using it's reader schema that was written using the _writer schema_.

Example schema:

.user-schema.avsc
[source, json]
----
include::../src/test/resources/user-schema.avsc[]
----

An example test to check this using https://github.com/sksamuel/avro4s[avro4s] would be something like:

.User.scala
[source, scala]
----
include::../src/test/scala/io/github/olib963/avrocheck/documentation/User.scala[tags=include]
----

.SerdeProperty.scala
[source, scala]
----
include::../src/test/scala/io/github/olib963/avrocheck/documentation/SerdeProperty.scala[tags=include]
}
----

Secondly it can be useful to write high level system property tests in terms of messages in and out. As an
example we will use the above schema to write a very simple application that signs up users with their favourite number.
If their favourite number is negative we give them a Â£10 sign up bonus and if it is between -1000 and -2000 we give them a double bonus.

[source, scala]
----
include::../src/test/scala/io/github/olib963/avrocheck/documentation/ApplicationProperty.scala[tags=include]
}
----

Due to the compatability features of avro, producers upstream of you should be able to make backwards
compatible changes without affecting your codebase. It is easy now to verify this by just updating the schema file. For example
by adding the following:

[source, json]
----
include::../src/test/resources/new-user-schema.avsc[tags=new_field, indent=-]
----

to the above schema, the example tests all still pass.

== How?

Import `io.github.olib963.avrocheck.\_` to get access to generation from avro schemas. Configuration can be provided
explicitly (default) or implicitly (by importing `io.github.olib963.avrocheck.Implicits._`). There is a utility function to read
schemas from a resource file. The schema you are passing currently must either be for a `RECORD` or a `UNION` of ``RECORD``s.

To change the default generators used by the `Gen` you can either explicitly pass the configuration or provide an implicit
arbitrary if using the implicit configuration.

[source, scala]
----
include::../src/test/scala/io/github/olib963/avrocheck/documentation/RecordGeneration.scala[]
----

=== Logical Types

Logical types will automatically be generated using the types:

* `timestamp-millis` -> `java.time.Instant`
* `timestamp-micros` -> `java.time.Instant`
* `time-millis` -> `java.time.LocalTime`
* `time-micros` -> `java.time.LocalTime`
* `date` -> `java.time.LocalDate`
* `uuid` -> `java.util.UUID`
* `decimal` -> `scala.math.BigDecimal`

If you want to provide overrides or implicit ``Arbitrary``s for logical types you must use these types.

If you don't want to go through the hassle of adding logical type conversions to your serialiser you can
set the configuration option `preserialiseLogicalTypes` to `true` and the values will automatically be turned into their underlying primitives.

[source, scala]
----
include::../src/test/scala/io/github/olib963/avrocheck/documentation/LogicalTypeConfiguration.scala[]
----

=== Overrides

If you want to customise the generation of your `GenericRecord` even more you can provide an implicit `Overrides` object.

[source, scala]
----
implicit val overrides: Overrides = selectUnion("Bar")
val gen = genFromSchema(schema)
----

Document:
- overrideKeys
- selectNamedUnion
- constantOverride
- generatorOverride
- arrayGenerationOverride
- arrayOverride

== Confluent Stack Warning

If you are using this library to run integration tests that integrate with Kafka and the confluent stack you should be aware 
of this:

=== Schema Registry with Unions

If you are generating messages that are a `UNION` of ``RECORD``s at the top level and you are using schema registry
you will want the union schema to be posted for your topic. This means you _cannot_ simply serialise the `GenericRecord`,
instead you will need to do this:

[source, scala]
----
import org.apache.avro.generic.GenericRecord
import org.scalacheck.Gen
import io.github.olib963.avrocheck.AvroCheck

class MyTest extends AvroCheck {

  // Schema of two records named "Foo" and "Bar" 
  private val unionSchema = schemaFromResource("my-union-schema.avsc")
  private val gen: Gen[GenericRecord] = genFromSchema(unionSchema)
  
  def serialise() {
    val genericRecord = gen.sample.get
    val serialiser = new KafkaAvroSerialiser(new MySchemaRegistryClient())
    
    // This is NOT what you want, this will post the schema for "Foo" or "Bar" only, not the union of both
    serialiser.serialise("my-topic", genericRecord)
    
    // This is what you want, this will post the union schema for the topic and serialise the 
    // genericRecord using "Foo" or "Bar" respectively
    serialiser.serialise("my-topic", new NonRecordContainer(unionSchema, genericRecord))
  }
}
----
